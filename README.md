Answers to exercises and code related to my study of
## "Reinforcement Learning" by Sutton & Barto (1998)

**Table of Contents**

1. Introduction
1. Evaluative Feedback
1. The Reinforcement Learning Problem
    1. Value Functions
        - Random Gridworld [agents/random_gridworld_agent.py](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/agents/random_gridworld_agent.py)
        - Gridworld Greedy Policy Evaluation [agents/greedy_gridworld_agent.py](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/agents/greedy_gridworld_agent.py)
        - Iterative Policy Evaluation in a grid world [gridworld_evaluate_policy.ipynb](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/gridworld_evaluate_policy.ipynb)
        - Exercise 3.10 [gridworld_evaluate_policy.ipynb](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/gridworld_evaluate_policy.ipynb)
        - Gridworld Policy Iteration [agents/policy_iteration_gridworld_agent.py](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/agents/policy_iteration_gridworld_agent.py)


1. Dynamic Programming
    1. Value Iteration
        - Exercise 4.8 [gamblers_problem.ipynb](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/gamblers_problem.ipynb)
        - Gridworld Value Iteration [agents/value_iteration_gridworld_agent.py](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/agents/value_iteration_gridworld_agent.py)

1. Monte Carlo Methods
    1. Monte Carlo Policy Evaluation
        - Example 5.1, Figure 5.1 [agents/monte_carlo_gridworld_agent.py](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/agents/monte_carlo_gridworld_agent.py)
    1. Monte Carlo Control
        - Monte Carlo ES, Example 5.3 [agents/monte_carlo_blackjack_agent.py](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/agents/monte_carlo_blackjack_agent.py)
    1. Exercise 5.6 [Exercise 5.6.exercises.ipynb](https://nbviewer.jupyter.org/github/PeterMitrano/sutton_and_barto_rl/blob/master/Exercise%205.6.ipynb) (mathjax won't render on github, so this link goes to nbviewer.jupyer.org)

1. Temporal-Difference Learning
    1. Exercise 6.1, 6.2, ... [td_0_exercises.ipynb](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/td_0_exercises.ipynb)
    1. Replicated figures 6.6, 6.7, and 6.8 [Optimality of TD0.ipynb](https://github.com/PeterMitrano/sutton_and_barto_rl/blob/master/Optimality%20of%20TD%200.ipynb)

1. Eligibility Trees
1. Generalization and Function Approximation
1. Planning and Learning
1. Dimensions of Reinforcemnet Learning
1. Case Studies
